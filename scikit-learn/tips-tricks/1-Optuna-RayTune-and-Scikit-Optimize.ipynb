{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f756128",
   "metadata": {},
   "source": [
    "# Optuna, Ray Tune, and Scikit-Optimize: Advanced Hyperparameter Optimization\n",
    "\n",
    "These are **smart alternatives to GridSearchCV/RandomizedSearchCV** that use **intelligent search strategies** instead of brute force or random sampling.\n",
    "\n",
    "## Quick Comparison Table\n",
    "\n",
    "| Library | Philosophy | Best For | Learning Curve | Speed |\n",
    "|---------|-----------|----------|----------------|-------|\n",
    "| **GridSearchCV** | Try everything | Small search spaces | ⭐⭐⭐⭐⭐ Easiest | ❌ Slowest |\n",
    "| **RandomizedSearchCV** | Random sampling | Medium spaces | ⭐⭐⭐⭐⭐ Easiest | ⭐⭐ Faster |\n",
    "| **scikit-optimize** | Bayesian optimization | Single machine, scikit-learn focused | ⭐⭐⭐⭐ Easy | ⭐⭐⭐ Smart |\n",
    "| **Optuna** | Bayesian + pruning | Production pipelines, flexibility | ⭐⭐⭐ Moderate | ⭐⭐⭐⭐ Very smart |\n",
    "| **Ray Tune** | Distributed + schedulers | Large-scale, clusters, deep learning | ⭐⭐ Complex | ⭐⭐⭐⭐⭐ Fastest (distributed) |\n",
    "\n",
    "---\n",
    "\n",
    "## The Core Problem They Solve\n",
    "\n",
    "**GridSearchCV** tries every combination:\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],      # 4 values\n",
    "    'max_depth': [3, 5, 10, 15, 20],          # 5 values\n",
    "    'min_samples_split': [2, 5, 10, 20],      # 4 values\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2]   # 4 values\n",
    "}\n",
    "# Total: 4 × 5 × 4 × 4 = 320 combinations × 5 folds = 1,600 model fits!\n",
    "```\n",
    "\n",
    "**Smart optimizers** learn from previous trials:\n",
    "```\n",
    "Trial 1:  n_estimators=100, max_depth=5  → AUC=0.75\n",
    "Trial 2:  n_estimators=200, max_depth=10 → AUC=0.82 ← Better!\n",
    "Trial 3:  Focus search around here...     → AUC=0.85 ← Even better!\n",
    "...\n",
    "Trial 50: Found optimal                   → AUC=0.87\n",
    "# Only 50 fits instead of 1,600, but smarter!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Scikit-Optimize (skopt)\n",
    "\n",
    "**Most similar to GridSearchCV** - drop-in replacement.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install scikit-optimize\n",
    "```\n",
    "\n",
    "### Basic Usage (Drop-in Replacement)\n",
    "\n",
    "```python\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define search space\n",
    "search_spaces = {\n",
    "    'n_estimators': (50, 300),              # Integer range\n",
    "    'max_depth': (3, 20),                    # Integer range\n",
    "    'min_samples_split': (2, 20),            # Integer range\n",
    "    'min_samples_leaf': (1, 10),             # Integer range\n",
    "    'max_features': ['sqrt', 'log2', None]   # Categorical\n",
    "}\n",
    "\n",
    "# Use like GridSearchCV!\n",
    "bayes_search = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    search_spaces,\n",
    "    n_iter=50,              # Number of parameter combinations to try\n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best score: {bayes_search.best_score_}\")\n",
    "print(f\"Best params: {bayes_search.best_params_}\")\n",
    "\n",
    "# Access best model (already retrained on full data)\n",
    "best_model = bayes_search.best_estimator_\n",
    "```\n",
    "\n",
    "**Key differences from GridSearchCV**:\n",
    "- ✅ Uses Gaussian Process to model parameter space\n",
    "- ✅ Intelligently picks next parameters to try\n",
    "- ✅ Same API as GridSearchCV (easy migration!)\n",
    "- ❌ Less flexible than Optuna/Ray Tune\n",
    "- ❌ No pruning/early stopping\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Optuna\n",
    "\n",
    "**Most popular** for production ML - flexible, powerful, great visualizations.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install optuna\n",
    "```\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna calls this function for each trial.\n",
    "    You define what to optimize.\n",
    "    \"\"\"\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Create and evaluate model\n",
    "    model = RandomForestClassifier(**params)\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc').mean()\n",
    "    \n",
    "    return score  # Optuna maximizes or minimizes this\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # or 'minimize'\n",
    "    study_name='rf_optimization',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)  # Bayesian optimization\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "print(f\"Best score: {study.best_value}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "```\n",
    "\n",
    "**Key features**:\n",
    "- ✅ **Pruning**: Stop bad trials early (saves computation)\n",
    "- ✅ **Flexible**: Works with any framework (sklearn, XGBoost, PyTorch)\n",
    "- ✅ **Visualization**: Built-in plots for analysis\n",
    "- ✅ **Persistence**: Save/resume studies\n",
    "- ✅ **Parallel**: Multiple workers on same study\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Ray Tune\n",
    "\n",
    "**Most scalable** - designed for distributed computing and deep learning.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install ray[tune]\n",
    "```\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "```python\n",
    "from ray import tune\n",
    "from ray.tune.sklearn import TuneSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define search space\n",
    "param_distributions = {\n",
    "    'n_estimators': tune.randint(50, 300),\n",
    "    'max_depth': tune.randint(3, 20),\n",
    "    'min_samples_split': tune.randint(2, 20),\n",
    "    'min_samples_leaf': tune.randint(1, 10),\n",
    "    'max_features': tune.choice(['sqrt', 'log2', None])\n",
    "}\n",
    "\n",
    "# Use like GridSearchCV\n",
    "tune_search = TuneSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions,\n",
    "    search_optimization=\"bayesian\",  # or \"random\", \"grid\"\n",
    "    n_trials=100,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tune_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best score: {tune_search.best_score_}\")\n",
    "print(f\"Best params: {tune_search.best_params_}\")\n",
    "```\n",
    "\n",
    "**Key features**:\n",
    "- ✅ **Distributed**: Multi-node clusters\n",
    "- ✅ **Schedulers**: ASHA, PBT for advanced strategies\n",
    "- ✅ **Deep learning**: Great with PyTorch, TensorFlow\n",
    "- ❌ More complex setup\n",
    "- ❌ Overkill for simple scikit-learn projects\n",
    "\n",
    "---\n",
    "\n",
    "## Integration with Your Complete Workflow\n",
    "\n",
    "Here's how these tools fit into your 7-step workflow. They **replace step 3** (Hyperparameter Tuning) but integrate with everything else.\n",
    "\n",
    "### Complete Workflow with Optuna + MLflow + Imblearn\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                            brier_score_loss)\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: DATA & SPLIT\n",
    "# ============================================================================\n",
    "# Assuming you have X, y loaded\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]}\")\n",
    "print(f\"Test size: {X_test.shape[0]}\")\n",
    "print(f\"Class distribution (train): {np.bincount(y_train)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: PREPROCESSING (defined in pipeline)\n",
    "# ============================================================================\n",
    "# We'll build this inside the objective function\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: HYPERPARAMETER TUNING with Optuna + MLflow\n",
    "# ============================================================================\n",
    "\n",
    "# Setup MLflow\n",
    "mlflow.set_experiment(\"complete-ml-workflow\")\n",
    "\n",
    "# Setup CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optimize entire pipeline: preprocessing + sampling + model\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # ---- PREPROCESSING ----\n",
    "        scaler_type = trial.suggest_categorical('scaler', ['standard', 'robust'])\n",
    "        \n",
    "        if scaler_type == 'standard':\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "        else:\n",
    "            from sklearn.preprocessing import RobustScaler\n",
    "            scaler = RobustScaler()\n",
    "        \n",
    "        mlflow.log_param(\"scaler\", scaler_type)\n",
    "        \n",
    "        # ---- SAMPLING (for imbalanced data) ----\n",
    "        use_smote = trial.suggest_categorical('use_smote', [True, False])\n",
    "        \n",
    "        steps = [('scaler', scaler)]\n",
    "        \n",
    "        if use_smote:\n",
    "            k_neighbors = trial.suggest_int('smote_k', 3, 10)\n",
    "            steps.append(('smote', SMOTE(k_neighbors=k_neighbors, random_state=42)))\n",
    "            mlflow.log_param(\"smote_k\", k_neighbors)\n",
    "        \n",
    "        mlflow.log_param(\"use_smote\", use_smote)\n",
    "        \n",
    "        # ---- MODEL HYPERPARAMETERS ----\n",
    "        model_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        steps.append(('classifier', RandomForestClassifier(**model_params)))\n",
    "        \n",
    "        # Build pipeline\n",
    "        pipeline = ImbPipeline(steps)\n",
    "        \n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # ---- CROSS-VALIDATION ----\n",
    "        scores = cross_val_score(\n",
    "            pipeline, X_train, y_train, \n",
    "            cv=cv, scoring='roc_auc', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        \n",
    "        mlflow.log_metric(\"cv_auc_mean\", mean_score)\n",
    "        mlflow.log_metric(\"cv_auc_std\", std_score)\n",
    "        \n",
    "        # ---- PRUNING (optional): Stop bad trials early ----\n",
    "        # Report intermediate results\n",
    "        trial.report(mean_score, step=0)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        return mean_score\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='ml-workflow-optimization',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=10)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=100, n_jobs=1)  # n_jobs=1 for MLflow safety\n",
    "\n",
    "# Print best results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST HYPERPARAMETERS FOUND\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best CV AUC: {study.best_value:.4f}\")\n",
    "print(f\"Best params:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: REBUILD BEST PIPELINE & CALIBRATION\n",
    "# ============================================================================\n",
    "\n",
    "# Rebuild pipeline with best params\n",
    "best_params = study.best_params\n",
    "\n",
    "# Scaler\n",
    "if best_params['scaler'] == 'standard':\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "else:\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "# Pipeline steps\n",
    "steps = [('scaler', scaler)]\n",
    "\n",
    "if best_params['use_smote']:\n",
    "    steps.append(('smote', SMOTE(k_neighbors=best_params['smote_k'], random_state=42)))\n",
    "\n",
    "# Model\n",
    "model_params = {\n",
    "    'n_estimators': best_params['n_estimators'],\n",
    "    'max_depth': best_params['max_depth'],\n",
    "    'min_samples_split': best_params['min_samples_split'],\n",
    "    'min_samples_leaf': best_params['min_samples_leaf'],\n",
    "    'max_features': best_params['max_features'],\n",
    "    'class_weight': best_params['class_weight'],\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "steps.append(('classifier', RandomForestClassifier(**model_params)))\n",
    "\n",
    "best_pipeline = ImbPipeline(steps)\n",
    "\n",
    "# Apply calibration\n",
    "calibrated_model = CalibratedClassifierCV(\n",
    "    best_pipeline,\n",
    "    method='sigmoid',  # Platt scaling\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining final calibrated model on all training data...\")\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: TEST EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predictions\n",
    "y_pred = calibrated_model.predict(X_test)\n",
    "y_proba = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "test_auc = roc_auc_score(y_test, y_proba)\n",
    "test_brier = brier_score_loss(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nTest AUC: {test_auc:.4f}\")\n",
    "print(f\"Test Brier Score: {test_brier:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"final-model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"test_auc\", test_auc)\n",
    "    mlflow.log_metric(\"test_brier\", test_brier)\n",
    "    mlflow.sklearn.log_model(calibrated_model, \"final_model\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {test_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Test Set')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png')\n",
    "mlflow.log_artifact('roc_curve.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Test Set')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pr_curve.png')\n",
    "mlflow.log_artifact('pr_curve.png')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: LEARNING CURVES\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "print(\"\\nGenerating learning curves...\")\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    calibrated_model.base_estimator,  # Use uncalibrated for speed\n",
    "    X_train, y_train,\n",
    "    cv=cv,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training score', marker='o')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
    "plt.plot(train_sizes, val_mean, label='Cross-validation score', marker='s')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2)\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves.png')\n",
    "mlflow.log_artifact('learning_curves.png')\n",
    "plt.show()\n",
    "\n",
    "# Diagnose\n",
    "gap = train_mean[-1] - val_mean[-1]\n",
    "if gap > 0.1:\n",
    "    print(\"\\n⚠️  HIGH VARIANCE (Overfitting)\")\n",
    "    print(\"   → Try: More data, regularization, simpler model\")\n",
    "elif val_mean[-1] < 0.75:\n",
    "    print(\"\\n⚠️  HIGH BIAS (Underfitting)\")\n",
    "    print(\"   → Try: More complex model, more features\")\n",
    "else:\n",
    "    print(\"\\n✅ Model is well-balanced\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: VALIDATION CURVES\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "print(\"\\nGenerating validation curve for max_depth...\")\n",
    "\n",
    "param_range = np.arange(3, 21, 2)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        min_samples_split=best_params['min_samples_split'],\n",
    "        random_state=42\n",
    "    ),\n",
    "    X_train, y_train,\n",
    "    param_name='max_depth',\n",
    "    param_range=param_range,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_range, train_mean, label='Training score', marker='o')\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
    "plt.plot(param_range, val_mean, label='Cross-validation score', marker='s')\n",
    "plt.fill_between(param_range, val_mean - val_std, val_mean + val_std, alpha=0.2)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.title('Validation Curve - max_depth')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('validation_curve.png')\n",
    "mlflow.log_artifact('validation_curve.png')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# OPTUNA VISUALIZATIONS (Bonus!)\n",
    "# ============================================================================\n",
    "\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# Optimization history\n",
    "fig = vis.plot_optimization_history(study)\n",
    "fig.write_html('optuna_history.html')\n",
    "mlflow.log_artifact('optuna_history.html')\n",
    "\n",
    "# Parameter importances\n",
    "fig = vis.plot_param_importances(study)\n",
    "fig.write_html('optuna_importances.html')\n",
    "mlflow.log_artifact('optuna_importances.html')\n",
    "\n",
    "# Parallel coordinate plot\n",
    "fig = vis.plot_parallel_coordinate(study)\n",
    "fig.write_html('optuna_parallel.html')\n",
    "mlflow.log_artifact('optuna_parallel.html')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WORKFLOW COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Best CV AUC: {study.best_value:.4f}\")\n",
    "print(f\"✅ Test AUC: {test_auc:.4f}\")\n",
    "print(f\"✅ All artifacts logged to MLflow\")\n",
    "print(f\"✅ View experiments: mlflow ui\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## MLflow Integration Patterns\n",
    "\n",
    "### Pattern 1: Auto-logging with Optuna\n",
    "\n",
    "```python\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "mlflow.set_experiment(\"auto-tracking\")\n",
    "\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=\"file:./mlruns\",\n",
    "    metric_name=\"auc\",\n",
    "    create_experiment=False,\n",
    "    mlflow_kwargs={\"nested\": True}\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=100,\n",
    "    callbacks=[mlflow_callback]  # Auto-logs everything!\n",
    ")\n",
    "```\n",
    "\n",
    "### Pattern 2: Manual Fine-grained Control\n",
    "\n",
    "```python\n",
    "def objective_with_mlflow(trial):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        params = {...}\n",
    "        \n",
    "        # Log everything you want\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"trial_number\", trial.number)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        score = cross_val_score(...)\n",
    "        \n",
    "        mlflow.log_metric(\"cv_score\", score.mean())\n",
    "        mlflow.log_metric(\"cv_std\", score.std())\n",
    "        \n",
    "        # Log artifacts\n",
    "        mlflow.log_artifact(\"plot.png\")\n",
    "        \n",
    "        return score.mean()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Each Tool\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│ YOUR SITUATION                    → RECOMMENDED TOOL        │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│ Learning / small projects         → GridSearchCV            │\n",
    "│ Want drop-in upgrade              → scikit-optimize         │\n",
    "│ Production ML pipelines           → Optuna + MLflow         │\n",
    "│ Need best visualizations          → Optuna                  │\n",
    "│ Distributed computing / clusters  → Ray Tune                │\n",
    "│ Deep learning projects            → Ray Tune or Optuna      │\n",
    "│ Budget: <100 trials               → RandomizedSearchCV      │\n",
    "│ Budget: 100-1000 trials           → Optuna                  │\n",
    "│ Budget: >1000 trials, distributed → Ray Tune                │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Recommendation for Your Workflow\n",
    "\n",
    "**Start with Optuna** because:\n",
    "\n",
    "1. ✅ **Easy migration**: Replace GridSearchCV with just a few lines\n",
    "2. ✅ **MLflow integration**: Built-in callbacks\n",
    "3. ✅ **Visualizations**: Understand what's happening\n",
    "4. ✅ **Pruning**: Save computation on bad trials\n",
    "5. ✅ **Flexibility**: Works with any model/framework\n",
    "6. ✅ **Production-ready**: Used by major companies\n",
    "\n",
    "**Upgrade path**:\n",
    "```\n",
    "GridSearchCV → Optuna → Ray Tune (if you need distributed)\n",
    "             → scikit-optimize (if you want minimal changes)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Want me to show:\n",
    "1. **How to resume interrupted Optuna studies** (save/load progress)?\n",
    "2. **Multi-objective optimization** (optimize multiple metrics simultaneously)?\n",
    "3. **Optuna with XGBoost/LightGBM** (tree-based models)?\n",
    "4. **Complete production deployment** with MLflow model registry?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d87d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
