{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f756128",
   "metadata": {},
   "source": [
    "# Optuna and Ray Tune: Advanced Hyperparameter Optimization\n",
    "\n",
    "These are **powerful alternatives** to `GridSearchCV` and `RandomizedSearchCV` that use **smarter search strategies**.\n",
    "\n",
    "## The Problem with Grid/Random Search\n",
    "\n",
    "```python\n",
    "# GridSearchCV tries EVERY combination (exhaustive)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "# Total trials: 4 √ó 4 = 16 (grows exponentially!)\n",
    "\n",
    "# RandomizedSearchCV samples randomly\n",
    "# Better, but still blind - doesn't learn from previous trials\n",
    "```\n",
    "\n",
    "**Limitations**:\n",
    "- ‚ùå No learning from past trials\n",
    "- ‚ùå Wastes computation on bad regions\n",
    "- ‚ùå Struggles with high-dimensional spaces (>10 hyperparameters)\n",
    "- ‚ùå Can't handle conditional parameters (e.g., kernel-specific params)\n",
    "\n",
    "## What Optuna and Ray Tune Do Differently\n",
    "\n",
    "Both use **Bayesian Optimization** and **smart sampling**:\n",
    "\n",
    "```\n",
    "Trial 1: Try random params ‚Üí Score = 0.75\n",
    "Trial 2: Try nearby params ‚Üí Score = 0.78 (getting warmer!)\n",
    "Trial 3: Focus search here ‚Üí Score = 0.82 (found good region!)\n",
    "Trial 4: Refine further ‚Üí Score = 0.84\n",
    "...\n",
    "Trial 50: Optimal found!\n",
    "\n",
    "vs GridSearch: Blindly tries all combinations\n",
    "```\n",
    "\n",
    "### Optuna\n",
    "- **From**: Preferred Networks (Japan)\n",
    "- **Philosophy**: Lightweight, Pythonic, easy to get started\n",
    "- **Strengths**: Simple API, great for single-node work, excellent pruning\n",
    "\n",
    "### Ray Tune\n",
    "- **From**: UC Berkeley (part of Ray ecosystem)\n",
    "- **Philosophy**: Distributed, scalable, production-grade\n",
    "- **Strengths**: Multi-node clusters, distributed training, schedulers\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Optuna Deep Dive\n",
    "\n",
    "### Basic Usage (Standalone)\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna calls this function for each trial\n",
    "    trial: object that suggests hyperparameters\n",
    "    \"\"\"\n",
    "    # Define search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    }\n",
    "    \n",
    "    # Create model with suggested params\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    \n",
    "    # Evaluate (Optuna will MINIMIZE this by default)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    return score  # Optuna tries to maximize/minimize this\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # or 'minimize'\n",
    "    study_name='rf_optimization',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)  # Tree-structured Parzen Estimator\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=100,  # Number of trials\n",
    "    timeout=3600,  # Or time limit (1 hour)\n",
    "    n_jobs=-1      # Parallel trials\n",
    ")\n",
    "\n",
    "# Best results\n",
    "print(f\"Best score: {study.best_value}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**1. Trial Object** - Suggests hyperparameters:\n",
    "\n",
    "```python\n",
    "# Different types of parameters\n",
    "trial.suggest_int('n_estimators', 10, 1000)  # Integer\n",
    "trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)  # Log scale\n",
    "trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])  # Discrete\n",
    "trial.suggest_uniform('C', 0.1, 100)  # Continuous uniform\n",
    "```\n",
    "\n",
    "**2. Samplers** - How to choose next trial:\n",
    "\n",
    "```python\n",
    "# TPE (Tree-structured Parzen Estimator) - most popular\n",
    "optuna.samplers.TPESampler()  # Bayesian optimization\n",
    "\n",
    "# Random (baseline)\n",
    "optuna.samplers.RandomSampler()\n",
    "\n",
    "# Grid (exhaustive)\n",
    "optuna.samplers.GridSampler(search_space)\n",
    "\n",
    "# CMA-ES (evolution strategy)\n",
    "optuna.samplers.CmaEsSampler()\n",
    "```\n",
    "\n",
    "**3. Pruning** - Stop bad trials early:\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "\n",
    "def objective_with_pruning(trial):\n",
    "    params = {...}\n",
    "    model = RandomForestClassifier(**params)\n",
    "    \n",
    "    # Evaluate each fold\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_fold_train = X_train[train_idx]\n",
    "        y_fold_train = y_train[train_idx]\n",
    "        X_fold_val = X_train[val_idx]\n",
    "        y_fold_val = y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        score = model.score(X_fold_val, y_fold_val)\n",
    "        \n",
    "        # Report intermediate score\n",
    "        trial.report(score, fold_idx)\n",
    "        \n",
    "        # Prune if this trial is clearly worse than others\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()  # Stop early, save computation!\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=optuna.pruners.MedianPruner(  # Prune if below median\n",
    "        n_startup_trials=5,  # Don't prune first 5 trials\n",
    "        n_warmup_steps=2     # Need at least 2 folds before pruning\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Integration with Your Workflow\n",
    "\n",
    "### A. Optuna + Scikit-learn Pipeline\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import optuna\n",
    "\n",
    "def objective_with_pipeline(trial):\n",
    "    \"\"\"\n",
    "    Optimize entire pipeline including preprocessing\n",
    "    \"\"\"\n",
    "    # Preprocessing params\n",
    "    scaler_type = trial.suggest_categorical('scaler', ['standard', 'minmax', 'robust'])\n",
    "    \n",
    "    if scaler_type == 'standard':\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        from sklearn.preprocessing import RobustScaler\n",
    "        scaler = RobustScaler()\n",
    "    \n",
    "    # Model params (conditional on kernel choice)\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    \n",
    "    model_params = {\n",
    "        'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
    "        'kernel': kernel\n",
    "    }\n",
    "    \n",
    "    if kernel == 'rbf':\n",
    "        model_params['gamma'] = trial.suggest_float('gamma', 1e-5, 1e-1, log=True)\n",
    "    elif kernel == 'poly':\n",
    "        model_params['degree'] = trial.suggest_int('degree', 2, 5)\n",
    "        model_params['gamma'] = trial.suggest_float('gamma', 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    # Build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('classifier', SVC(**model_params, probability=True, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Evaluate\n",
    "    score = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_with_pipeline, n_trials=100)\n",
    "```\n",
    "\n",
    "### B. Optuna + Imbalanced-learn\n",
    "\n",
    "```python\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def objective_with_imbalanced(trial):\n",
    "    \"\"\"\n",
    "    Optimize sampling strategy + model together\n",
    "    \"\"\"\n",
    "    # Sampling strategy\n",
    "    sampling_strategy = trial.suggest_categorical(\n",
    "        'sampling', \n",
    "        ['none', 'smote', 'undersample', 'both']\n",
    "    )\n",
    "    \n",
    "    steps = [('scaler', StandardScaler())]\n",
    "    \n",
    "    if sampling_strategy == 'smote':\n",
    "        k_neighbors = trial.suggest_int('smote_k', 3, 10)\n",
    "        steps.append(('sampler', SMOTE(k_neighbors=k_neighbors, random_state=42)))\n",
    "    \n",
    "    elif sampling_strategy == 'undersample':\n",
    "        sampling_ratio = trial.suggest_float('under_ratio', 0.5, 1.0)\n",
    "        steps.append(('sampler', RandomUnderSampler(\n",
    "            sampling_strategy=sampling_ratio, \n",
    "            random_state=42\n",
    "        )))\n",
    "    \n",
    "    elif sampling_strategy == 'both':\n",
    "        # SMOTE then undersample\n",
    "        steps.append(('smote', SMOTE(random_state=42)))\n",
    "        steps.append(('under', RandomUnderSampler(random_state=42)))\n",
    "    \n",
    "    # Model params\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None])\n",
    "    }\n",
    "    \n",
    "    steps.append(('classifier', RandomForestClassifier(**params, random_state=42)))\n",
    "    \n",
    "    pipeline = ImbPipeline(steps)\n",
    "    score = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_with_imbalanced, n_trials=150)\n",
    "```\n",
    "\n",
    "### C. Optuna + MLflow Integration\n",
    "\n",
    "**MLflow** tracks experiments, parameters, metrics, and artifacts.\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")  # or remote server\n",
    "mlflow.set_experiment(\"hyperparameter-optimization\")\n",
    "\n",
    "def objective_with_mlflow(trial):\n",
    "    \"\"\"\n",
    "    Optuna trial with MLflow tracking\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    }\n",
    "    \n",
    "    # Start MLflow run for this trial\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "        \n",
    "        # Cross-validation\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"cv_auc_mean\", mean_score)\n",
    "        mlflow.log_metric(\"cv_auc_std\", std_score)\n",
    "        \n",
    "        # Log model\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "    return mean_score\n",
    "\n",
    "# Create study with MLflow callback\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=\"file:./mlruns\",\n",
    "    metric_name=\"auc\"\n",
    ")\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective_with_mlflow, \n",
    "    n_trials=100,\n",
    "    callbacks=[mlflow_callback]  # Auto-logs to MLflow\n",
    ")\n",
    "\n",
    "# After optimization, retrieve best run\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best score: {study.best_value}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "# Load best model from MLflow\n",
    "best_run_id = study.best_trial.user_attrs['mlflow_run_id']\n",
    "best_model = mlflow.sklearn.load_model(f\"runs:/{best_run_id}/model\")\n",
    "```\n",
    "\n",
    "**What MLflow gives you**:\n",
    "- üìä **Experiment tracking**: All trials logged automatically\n",
    "- üìà **Metric visualization**: Compare trials, plot learning curves\n",
    "- üíæ **Model versioning**: Save and load models easily\n",
    "- üîç **Reproducibility**: Every parameter/metric/artifact tracked\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Complete Workflow Integration\n",
    "\n",
    "Here's how everything fits together:\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "import mlflow\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Setup\n",
    "mlflow.set_experiment(\"complete-ml-workflow\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def complete_objective(trial):\n",
    "    \"\"\"\n",
    "    Full pipeline: imbalanced data ‚Üí model ‚Üí calibration\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # 1. SAMPLING STRATEGY\n",
    "        use_smote = trial.suggest_categorical('use_smote', [True, False])\n",
    "        \n",
    "        steps = [('scaler', StandardScaler())]\n",
    "        \n",
    "        if use_smote:\n",
    "            k_neighbors = trial.suggest_int('smote_k', 3, 10)\n",
    "            steps.append(('smote', SMOTE(k_neighbors=k_neighbors, random_state=42)))\n",
    "            mlflow.log_param(\"smote_k\", k_neighbors)\n",
    "        \n",
    "        mlflow.log_param(\"use_smote\", use_smote)\n",
    "        \n",
    "        # 2. MODEL HYPERPARAMETERS\n",
    "        model_params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        steps.append(('classifier', RandomForestClassifier(**model_params)))\n",
    "        \n",
    "        # Build pipeline\n",
    "        pipeline = ImbPipeline(steps)\n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # 3. EVALUATE UNCALIBRATED MODEL\n",
    "        uncal_scores = cross_val_score(\n",
    "            pipeline, X_train, y_train, cv=cv, scoring='roc_auc'\n",
    "        )\n",
    "        uncal_mean = uncal_scores.mean()\n",
    "        \n",
    "        mlflow.log_metric(\"uncalibrated_auc\", uncal_mean)\n",
    "        mlflow.log_metric(\"uncalibrated_auc_std\", uncal_scores.std())\n",
    "        \n",
    "        # 4. CALIBRATION\n",
    "        calibration_method = trial.suggest_categorical('calibration', ['sigmoid', 'isotonic'])\n",
    "        \n",
    "        calibrated_pipeline = CalibratedClassifierCV(\n",
    "            pipeline,\n",
    "            method=calibration_method,\n",
    "            cv=cv,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        mlflow.log_param(\"calibration_method\", calibration_method)\n",
    "        \n",
    "        # 5. EVALUATE CALIBRATED MODEL\n",
    "        cal_scores = cross_val_score(\n",
    "            calibrated_pipeline, X_train, y_train, cv=cv, scoring='roc_auc'\n",
    "        )\n",
    "        cal_mean = cal_scores.mean()\n",
    "        \n",
    "        mlflow.log_metric(\"calibrated_auc\", cal_mean)\n",
    "        mlflow.log_metric(\"calibrated_auc_std\", cal_scores.std())\n",
    "        \n",
    "        # 6. FINAL TRAINING & LOGGING\n",
    "        calibrated_pipeline.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(calibrated_pipeline, \"calibrated_model\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_auc = roc_auc_score(y_test, calibrated_pipeline.predict_proba(X_test)[:, 1])\n",
    "        mlflow.log_metric(\"test_auc\", test_auc)\n",
    "        \n",
    "        return cal_mean  # Optimize calibrated CV AUC\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='complete-workflow',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=10)\n",
    ")\n",
    "\n",
    "study.optimize(complete_objective, n_trials=200, n_jobs=1)  # n_jobs=1 for MLflow\n",
    "\n",
    "# Get best configuration\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best CV AUC: {study.best_value:.4f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "# Retrain final model with best params\n",
    "best_params = study.best_params\n",
    "# ... rebuild pipeline with best_params ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Optuna Visualization\n",
    "\n",
    "```python\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# After study.optimize(...)\n",
    "\n",
    "# 1. Optimization history\n",
    "fig = vis.plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "# 2. Parameter importances (which params matter most?)\n",
    "fig = vis.plot_param_importances(study)\n",
    "fig.show()\n",
    "\n",
    "# 3. Parallel coordinate plot (see relationships between params)\n",
    "fig = vis.plot_parallel_coordinate(study)\n",
    "fig.show()\n",
    "\n",
    "# 4. Slice plot (how each param affects score)\n",
    "fig = vis.plot_slice(study)\n",
    "fig.show()\n",
    "\n",
    "# 5. Contour plot (2D interactions)\n",
    "fig = vis.plot_contour(study, params=['n_estimators', 'max_depth'])\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Ray Tune (Quick Overview)\n",
    "\n",
    "**Ray Tune** is more complex but scales to clusters:\n",
    "\n",
    "```python\n",
    "from ray import tune\n",
    "from ray.tune.sklearn import TuneSearchCV\n",
    "\n",
    "# Define search space\n",
    "param_distributions = {\n",
    "    'n_estimators': tune.randint(50, 300),\n",
    "    'max_depth': tune.randint(3, 15),\n",
    "    'learning_rate': tune.loguniform(0.01, 0.3)\n",
    "}\n",
    "\n",
    "# Use like GridSearchCV\n",
    "tune_search = TuneSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions,\n",
    "    search_optimization=\"bayesian\",  # Bayesian optimization\n",
    "    n_trials=100,\n",
    "    cv=5,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "tune_search.fit(X_train, y_train)\n",
    "print(tune_search.best_params_)\n",
    "```\n",
    "\n",
    "**When to use Ray Tune**:\n",
    "- Multi-node clusters\n",
    "- Distributed deep learning\n",
    "- Need advanced schedulers (ASHA, PBT)\n",
    "- Production ML infrastructure\n",
    "\n",
    "**When to use Optuna**:\n",
    "- Single machine / small cluster\n",
    "- Quick prototyping\n",
    "- Simpler API needed\n",
    "- Scikit-learn focused\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Comparison Summary\n",
    "\n",
    "| Feature | GridSearchCV | RandomizedSearchCV | Optuna | Ray Tune |\n",
    "|---------|-------------|-------------------|--------|----------|\n",
    "| **Search Strategy** | Exhaustive grid | Random sampling | Bayesian (smart) | Bayesian (smart) |\n",
    "| **Efficiency** | ‚≠ê Worst | ‚≠ê‚≠ê Better | ‚≠ê‚≠ê‚≠ê‚≠ê Great | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Best |\n",
    "| **Ease of Use** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
    "| **Scalability** | Single node | Single node | Single/small cluster | Large clusters |\n",
    "| **Pruning** | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ |\n",
    "| **Conditional Params** | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ |\n",
    "| **MLflow Integration** | Manual | Manual | ‚úÖ Built-in | ‚úÖ Built-in |\n",
    "| **Visualization** | ‚ùå | ‚ùå | ‚úÖ Excellent | ‚úÖ Good |\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use What?\n",
    "\n",
    "```\n",
    "Small search space (<20 trials):\n",
    "‚Üí GridSearchCV (simple, complete)\n",
    "\n",
    "Medium search (20-100 trials):\n",
    "‚Üí RandomizedSearchCV (good baseline)\n",
    "\n",
    "Large search (100+ trials), single machine:\n",
    "‚Üí Optuna (best ROI)\n",
    "\n",
    "Very large search, distributed:\n",
    "‚Üí Ray Tune (scales best)\n",
    "\n",
    "Complex pipelines + tracking:\n",
    "‚Üí Optuna + MLflow (production-ready)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Want me to show:\n",
    "1. **How to resume interrupted Optuna studies** (save/load progress)?\n",
    "2. **Multi-objective optimization** (optimize AUC AND calibration together)?\n",
    "3. **Distributed Optuna** (multiple workers)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d87d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
